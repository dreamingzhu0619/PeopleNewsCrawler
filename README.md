# PeopleNewsCrawler
一个新手友好的人民网新闻批量爬取工具，支持按关键词、时间范围筛选，自动去重、异步爬取（速度快），最终结果保存为Excel/CSV格式，可直接用于数据分析。

## 功能特点 ✨
- **简单易用**：只需修改少量参数（时间范围、关键词、Cookie），即可运行
- **高效爬取**：采用异步请求+多线程解析，批量处理新闻，比同步爬取快10倍
- **自动去重**：基于“日期+标题指纹”生成唯一标识，避免重复保存
- **智能筛选**：可自定义关键词，只保留含目标关键词的新闻
- **断点续爬**：自动保存缓存，程序中断后重新运行可恢复之前的爬取进度
- **数据整洁**：自动清理文本、提取纯正文，保存标题、时间、URL、正文、关键词等结构化数据

## 环境准备 🛠️
### 1. 安装Python
确保你的电脑安装了Python 3.8+（推荐3.9/3.10），下载地址：https://www.python.org/downloads/

### 2. 安装依赖库
pip install requests pandas beautifulsoup4 aiohttp chardet lxml openpyxl
--requests：发送 HTTP 请求
--pandas：处理 / 保存数据（Excel/CSV）
--beautifulsoup4：解析 HTML 提取正文
--aiohttp：异步请求
--chardet：自动识别文本编码（解决中文乱码）
--lxml：HTML 解析器
--openpyxl：Excel 文件写入支持
## 使用步骤 🚀
### 1. 下载代码
将本项目克隆到本地，或直接复制people_news_crawler.py文件到电脑。
### 2. 获取人民网 Cookie（关键步骤！）
Cookie 是验证你身份的信息，没有 Cookie 会导致 API 请求失败：
打开浏览器（推荐 Chrome/Firefox），访问人民网搜索页面：https://search.people.cn/
登录你的人民网账号（没有则注册一个）
按F12打开开发者工具 → 切换到「Network（网络）」标签 → 刷新页面
找到任意一个请求（比如search）→ 点击请求 → 找到「Request Headers（请求头）」→ 复制Cookie字段的全部内容
### 3. 修改配置参数
用记事本 / VS Code 打开people_news_crawler.py，修改以下核心参数（其他参数可默认）：
''' python'''
# ========== 时间范围（必填） ==========
START_DATE = datetime(2024, 1, 1)  # 爬取开始日期：年-月-日
END_DATE = datetime(2024, 4, 1)    # 爬取结束日期：年-月-日

# ========== 搜索关键词（必填） ==========
SEARCH_KEY = "政策"  # 比如改成"经济" "科技" "教育"

# ========== API 配置（必填：替换成你的Cookie） ==========
HEADERS = {
    "Content-Type": "application/json;charset=UTF-8",
    "User-Agent": "Mozilla/5.0",
    "Cookie": "这里替换成你刚才复制的Cookie"  # 关键！必须替换
}

# ========== 正文关键词过滤（可选：添加/删除你关注的词） ==========
KEYWORD_SET = {
    "经济", "金融", "商业", "不确定", "政策", "政府", "改革", "监管", "财政", "央行"
}

### 4. 运行代码
打开命令行，切换到代码所在文件夹，执行：
''' python '''
python people_news_crawler.py

运行过程中会显示爬取进度（时间范围、页码、新增新闻数）
爬取完成后，文件会保存到你的桌面：
people_news_final_deduped.xlsx：最终结果（Excel 格式，可直接用 Excel 打开）
people_news_backup_final_deduped.csv：缓存文件（用于断点续爬）

### 5.输出结果
Excel/CSV 文件包含以下列：
列名	说明
标题	新闻标题（已清理多余空格）
时间	发布日期（格式：YYYY-MM-DD）
URL	新闻详情页链接
正文	纯文本新闻正文（无广告、无多余标签）
字数	正文长度（字符数）
命中关键词	正文中匹配到的关键词（用逗号分隔）


### 6.注意事项 ⚠️
Cookie 有效期：Cookie 会过期（一般几天到几周），如果爬取时出现 “API 请求失败”，请重新获取 Cookie。
爬取频率：代码已设置 0.5 秒的爬取间隔，请勿修改为过快（比如 0 秒），否则可能被人民网封禁 IP。
时间范围：建议每次爬取时间范围不超过 3 个月，避免 API 限制。
关键词设置：KEYWORD_SET是正文过滤关键词，只保留含这些词的新闻，可根据需求添加 / 删除。
合规性：本工具仅用于学习和研究，请勿用于商业用途，爬取时请遵守人民网的robots.txt协议和相关规定，不要过度爬取给服务器造成压力。


### 免责声明 📝
本项目仅为学习 Python 爬虫技术提供示例，请勿用于任何违反法律法规或网站规定的行为。使用者应自行承担因使用本工具而产生的所有法律责任，作者不承担任何相关责任。
如有问题可以自行询问AI解答，因为主播本人（准确来说是主播的同学）也是用ai改的
